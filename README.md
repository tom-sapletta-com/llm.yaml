# llm.yaml
manifest realizacji projekt√≥w przy u≈ºyciu LLM

## Szkic
podczas wieloletniej pracy rozwijania oprogramowania z LLM-ami doszed≈Çem do kilku wniosk√≥w, kt√≥re optymalizujƒÖ czas dostarczenia oczekiwanych rezultat√≥w:
- specyfikacja nie jest wystarczajƒÖca do tworzenia
- konieczne jest okre≈õlenie wektora rozwoju, czƒôsto przy refaktoryzacji dochodzi do koneicznosci okre≈õlenia wiƒôkszej ilo≈õci tets√≥w i twoprzy siƒô g√≥¬©ka zada≈Ñ
- Gdy dochodzimy do tej g√≥rki zada≈Ñ potrzebujemy zadecydowaƒá czy stworzyƒánowy projekt od nowa z aktualna specyfikacja i okresleniem punktu wektoru oczekiwa≈Ñ
- ka≈ºda iteracja wymaga kolejnego folderu, dlatego ≈º ≈Çatwiej jest co≈õ stworzyƒá od nowa majƒÖc w g≈Çowie aktualne do≈õwiadczenia i niepowodzenia
- to niepowodzenia kszta≈ÇtujƒÖ wektor okre≈õlajƒÖcy zakres prac i kierunek rozwoju
- kolejne iteracje nie powoinny polegaƒá na zmianie aktualnych plik√≥w, ale ca≈Çej struktury, co jest nieintuicyjne dla cz≈Çowieka, kt√≥ry z zasady chce naprawiƒá to co nie dzia≈Ça, gdy≈º okontek≈õt jest ≈õci≈õle okre≈õlony, jednak dla LLM to zbyt du≈ºy wydatek energetyczny i muszƒÖ skupiaƒá siƒô na protszzych modelach, dlatego konieczny jest manifest u≈ÇatwiajƒÖcy radzenie sobie z konkretnymi problemami poporzez ich dzielnie na mniejsze i realziacje ich w nowych folderach
- przyk≈Çadowo zamiast naprawiaƒá to co nie dzia≈Ça w aktualnej wersji mamy do wyboru:
  - stworzenie od nowa tego co ju≈º jest z poszerzonym promptem lub
  - stworzenie kolejnego komponentu, kt√≥ry bƒôdzie korzysta≈Ç z tego, tk√≥ry aktualnie nie dzia≈Ça i LLM z kontekstu u≈ºycia bƒôdzie siƒô stara≈Ç dopasowaƒá stary kod peirwszego komponentu aby zaczƒÖ≈Ç poorawnie funkcjonowaƒá lub napisze/nadpoisze nowy komponent




## Podsumowanie

Wnioski z pracy z LLM w projektach programistycznych

1. **Specyfikacja to dopiero poczƒÖtek**

   * Sama specyfikacja nie wystarczy, aby LLM generowa≈Çy w pe≈Çni funkcjonalny kod.
   * Trzeba r√≥wnie≈º okre≈õliƒá **kierunek rozwoju projektu** (‚Äûwektor oczekiwa≈Ñ‚Äù), kt√≥ry pozwala decydowaƒá, co jest priorytetem w kolejnych iteracjach.

2. **Refaktoryzacja generuje g√≥rkƒô zada≈Ñ**

   * Podczas refaktoryzacji czƒôsto okazuje siƒô, ≈ºe potrzeba wiƒôcej test√≥w i dodatkowych funkcji.
   * To tworzy ‚Äûg√≥rkƒô zada≈Ñ‚Äù, kt√≥rƒÖ trzeba oceniƒá: czy lepiej kontynuowaƒá obecny projekt, czy zaczƒÖƒá od nowa.

3. **Decyzja: nowy projekt vs kontynuacja**

   * Czƒôsto bardziej efektywne jest rozpoczƒôcie nowego projektu z aktualnƒÖ specyfikacjƒÖ i nowym punktem startowym, ni≈º pr√≥ba naprawy istniejƒÖcego kodu.
   * Dziƒôki temu unikamy nagromadzenia ‚Äûhistorycznych‚Äù b≈Çƒôd√≥w i nieoptymalnych struktur.

4. **Iteracje jako nowe foldery / struktury**

   * Ka≈ºda iteracja powinna byƒá traktowana jako osobny projekt, a nie poprawka w istniejƒÖcych plikach.
   * Ludzki instynkt: ‚Äûnaprawiƒá to, co nie dzia≈Ça‚Äù jest nieoptymalny dla LLM, poniewa≈º kontekst staje siƒô zbyt rozbudowany.
   * Lepsze: dzieliƒá problemy na mniejsze czƒô≈õci i realizowaƒá je w **nowych strukturach**, minimalizujƒÖc zale≈ºno≈õci od wcze≈õniejszych iteracji.

5. **Niepowodzenia kszta≈ÇtujƒÖ kierunek rozwoju**

   * B≈Çƒôdy i nieudane iteracje nie sƒÖ stratƒÖ czasu ‚Äì to kluczowy element wyznaczania kolejnych krok√≥w i punkt√≥w w wektorze rozwoju.
   * PozwalajƒÖ LLM skupiƒá siƒô na prostszych, bardziej precyzyjnych modelach problemu.

6. **Manifest dla pracy z LLM**

   * Stworzenie dokumentu / zasad, kt√≥re pomagajƒÖ radziƒá sobie z problemami poprzez:

     * dzielenie ich na mniejsze, ≈Çatwiejsze zadania,
     * realizacjƒô ich w nowych folderach/projektach,
     * zachowanie jasnego punktu startowego i minimalizacji kontekstu z poprzednich iteracji.


## Przyk≈Çady


- manifest w formacie YAML, kt√≥ry LLM ma czytaƒá i interpretowaƒá
- Ka≈ºdy punkt ma **opis**, **priorytet** oraz **zalecane dzia≈Çania**, ≈ºeby model wiedzia≈Ç, co jest istotne w danej iteracji. 


### Manifest pracy z LLM ‚Äì YAML

```yaml
project_manifest:
  metadata:
    project_name: "ExampleProject"
    current_iteration: 3
    vector_of_expectations: "Refaktoryzacja modu≈Ç√≥w API i uproszczenie test√≥w"
  
  principles:
    - id: 1
      title: "Specyfikacja to dopiero poczƒÖtek"
      description: "Sama specyfikacja nie wystarcza. Nale≈ºy wskazaƒá wektor rozwoju i priorytety."
      priority: high
      LLM_hint: "Skup siƒô na okre≈õleniu kierunku rozwoju projektu."
      example_use: |
        - "Okre≈õl kierunek rozwoju projektu."
        - "Zidentyfikuj funkcje i modu≈Çy kluczowe dla obecnej iteracji."

    - id: 2
      title: "Refaktoryzacja generuje g√≥rkƒô zada≈Ñ"
      description: "Refaktoryzacja czƒôsto ujawnia dodatkowe wymagania i testy."
      priority: medium
      LLM_hint: "Zidentyfikuj nowe testy potrzebne do poprawnej refaktoryzacji."
      example_use: |
        - "Zidentyfikuj nowe testy potrzebne do poprawnej refaktoryzacji."
        - "Oce≈Ñ, czy warto kontynuowaƒá stary projekt, czy zaczƒÖƒá nowy."

    - id: 3
      title: "Nowy projekt vs kontynuacja"
      description: "Rozpoczƒôcie nowego projektu mo≈ºe byƒá bardziej efektywne ni≈º poprawa starego."
      priority: high
      LLM_hint: "Oce≈Ñ, czy lepiej rozpoczƒÖƒá nowy projekt, czy kontynuowaƒá obecny."
      example_use: |
        - "Utw√≥rz nowƒÖ strukturƒô projektu, je≈õli obecna jest zbyt z≈Ço≈ºona."
        - "Zachowaj do≈õwiadczenia z poprzednich iteracji w dokumentacji."

    - id: 4
      title: "Iteracje jako nowe foldery/projekty"
      description: "Ka≈ºda iteracja powinna byƒá osobnym projektem, unikajƒÖc zmiany starych plik√≥w."
      priority: high
      LLM_hint: "Tw√≥rz nowy folder dla ka≈ºdej iteracji."
      example_use: |
        - "Tw√≥rz nowy folder dla ka≈ºdej iteracji."
        - "Podziel problem na mniejsze zadania realizowane w nowych strukturach."

    - id: 5
      title: "Niepowodzenia kszta≈ÇtujƒÖ kierunek rozwoju"
      description: "B≈Çƒôdy i nieudane iteracje sƒÖ ≈∫r√≥d≈Çem informacji o kierunku prac."
      priority: medium
      LLM_hint: "Dokumentuj niepowodzenia i wyciƒÖgaj z nich wnioski."
      example_use: |
        - "Dokumentuj niepowodzenia i wyciƒÖgaj z nich wnioski."
        - "Uaktualniaj wektor oczekiwa≈Ñ na podstawie do≈õwiadcze≈Ñ."

    - id: 6
      title: "Manifest jako przewodnik LLM"
      description: "Zasady manifestu pomagajƒÖ LLM w efektywnej realizacji zada≈Ñ."
      priority: high
      LLM_hint: "Dziel problemy na mniejsze, ≈Çatwiejsze do wykonania zadania."
      example_use: |
        - "Dziel problemy na mniejsze, ≈Çatwiejsze do wykonania zadania."
        - "Realizuj zadania w nowych folderach, aby minimalizowaƒá kontekst z poprzednich iteracji."

```



### Przyk≈Çad u≈ºycia YAML przez LLM

Za≈Ç√≥≈ºmy, ≈ºe LLM dostaje zadanie: **Refaktoryzacja modu≈Çu API w iteracji 3**.

1. Model odczytuje manifest i widzi:

   * `current_iteration: 3`
   * `vector_of_expectations: Refaktoryzacja modu≈Ç√≥w API i uproszczenie test√≥w`
   * Priorytetowe zasady: `Specyfikacja to dopiero poczƒÖtek`, `Iteracje jako nowe foldery`, `Nowy projekt vs kontynuacja`.

2. Model mo≈ºe zaplanowaƒá dzia≈Çania:

```yaml
iteration_plan:
  iteration: 3
  actions:
    - "Utw√≥rz nowy folder dla iteracji 3."
    - "Zidentyfikuj kluczowe modu≈Çy API wymagajƒÖce refaktoryzacji."
    - "Dodaj brakujƒÖce testy dla modu≈Ç√≥w API."
    - "Dokumentuj wszelkie problemy i niepowodzenia."
    - "Na podstawie do≈õwiadcze≈Ñ z poprzednich iteracji zaktualizuj wektor oczekiwa≈Ñ."
```

3. Efekt: LLM dzia≈Ça zgodnie z manifestem, unika nadmiernego kontekstu z poprzednich iteracji i skupia siƒô na priorytetach.



## Ollama + manifest llm yaml

jak rozpoczƒÖƒá pracƒô z Ollama i manifestami YAML, aby efektywnie zarzƒÖdzaƒá iteracjami w projektach programistycznych?

---

## üß∞ Krok 1: Instalacja Ollama

### Na systemie Linux:

1. **Pobierz i zainstaluj Ollama:**

   ```bash
   curl -fsSL https://ollama.com/install.sh | sh
   ```

2. **Sprawd≈∫, czy instalacja siƒô powiod≈Ça:**

   ```bash
   ollama --version
   ```

   Je≈õli zobaczysz wersjƒô Ollama, oznacza to, ≈ºe instalacja przebieg≈Ça pomy≈õlnie.


3. **Zainicjuj serwer Ollama:**

   ```bash
   ollama serve
   ```

4. **Przeka≈º manifest jako prompt do Ollama:**

   ```bash
   ollama chat --prompt "$(cat manifest.yaml)"
   ```

   Ollama odczyta manifest i na jego podstawie wygeneruje plan iteracji lub dzia≈Çania w oparciu o zawarte zasady.




## üîπ Koncepcja automatyzacji

1. **Zbierz wszystkie wyniki narzƒôdzi** w formacie tekstowym lub JSON:

   * `pytest --json-report` ‚Üí raport JSON z test√≥w
   * `eslint -f json` ‚Üí raport JSON dla JS/TS
   * `flake8 --format=json` ‚Üí raport JSON dla Pythona
2. **Po≈ÇƒÖcz te raporty** w jednƒÖ strukturƒô, np. JSON z b≈Çƒôdami i metadanymi.
3. **Przeka≈º ten JSON + manifest YAML** do LLM jako prompt.
4. LLM analizuje:

   * b≈Çƒôdy / niepowodzenia
   * priorytety z manifestu (`LLM_hint`, `priority`)
   * wektor rozwoju i aktualnƒÖ iteracjƒô
5. LLM generuje **plan naprawy**, np. w YAML lub JSON gotowy do automatycznej realizacji.

---

## üîπ Przyk≈Çad w jednej linii (bash + Ollama)

Zak≈ÇadajƒÖc, ≈ºe masz:

* `manifest.yaml`
* `test_report.json` (wyniki test√≥w, lint√≥w itd.)

```bash
ollama chat --prompt "$(echo "Manifest YAML:"; cat manifest.yaml; echo; echo "B≈Çƒôdy i raporty:"; cat test_report.json; echo; echo "Na podstawie manifestu i raport√≥w, wygeneruj plan naprawy w YAML.")"
```

* `$(echo ...)` ‚Äì scala manifest i raport w jednƒÖ wiadomo≈õƒá.
* LLM otrzymuje kontekst manifestu i konkretnych b≈Çƒôd√≥w, wiƒôc mo≈ºe wygenerowaƒá **plan iteracji i naprawy**.

---

## üîπ Przyk≈Çad w Pythonie 

```python
import json
from pathlib import Path
from ollama import Chat

# Wczytaj manifest i raport
manifest = Path("manifest.yaml").read_text()
report = Path("test_report.json").read_text()

prompt = f"""
Manifest YAML:
{manifest}

B≈Çƒôdy i raporty:
{report}

Na podstawie manifestu i raport√≥w, wygeneruj plan naprawy w YAML.
"""

# Wywo≈Çanie Ollama
response = Chat("your_model_name").send(prompt)
print(response.text)
```

Efekt: LLM wygeneruje **iteracyjny plan dzia≈Ça≈Ñ**, uwzglƒôdniajƒÖcy priorytety i zalecenia z manifestu oraz konkretne problemy wykryte przez narzƒôdzia.


[![Terminal GPT: U≈ºyj ChatGPT w terminalu Linux bez kluczy API](https://tse2.mm.bing.net/th/id/OIP.a-367W9ib2ZqDIpy5cRxQAHaEK?pid=Api)](https://pl.ubunlog.com/terminal-gpt-tgpt/?utm_source=chatgpt.com)



## Projekt

1. Zbiera raporty z test√≥w i lint√≥w.
2. Scala je z manifestem YAML.
3. Wysy≈Ça do Ollama jako prompt.
4. Zapisuje wynikowy plan naprawy w YAML.

---

### üîπ Struktura projektu

```
project/
‚îú‚îÄ‚îÄ manifest.yaml
‚îú‚îÄ‚îÄ run_tests.sh
‚îú‚îÄ‚îÄ collect_reports.py
‚îú‚îÄ‚îÄ generate_plan.py
‚îî‚îÄ‚îÄ reports/
    ‚îú‚îÄ‚îÄ test_report.json
    ‚îî‚îÄ‚îÄ lint_report.json
```

---

### üîπ 1Ô∏è‚É£ Skrypt do uruchamiania test√≥w i lint√≥w (`run_tests.sh`)

```bash
#!/bin/bash
mkdir -p reports

# Uruchom testy Pythona i zapisz JSON
pytest --json-report --json-report-file=reports/test_report.json

# Uruchom linter Pythona i zapisz JSON
flake8 --format=json > reports/lint_report.json || true

echo "Raporty zapisane w folderze reports/"
```

> `|| true` zabezpiecza przed przerwaniem skryptu przy b≈Çƒôdach lint.

---

### üîπ 2Ô∏è‚É£ Skrypt do ≈ÇƒÖczenia raport√≥w (`collect_reports.py`)

```python
import json
from pathlib import Path

# Wczytaj raporty
test_report = json.loads(Path("reports/test_report.json").read_text())
lint_report = json.loads(Path("reports/lint_report.json").read_text())

# Po≈ÇƒÖcz w jeden obiekt
combined_report = {
    "test_report": test_report,
    "lint_report": lint_report
}

# Zapisz do pliku JSON
Path("reports/combined_report.json").write_text(json.dumps(combined_report, indent=2))
print("Po≈ÇƒÖczony raport zapisany jako reports/combined_report.json")
```

---

### üîπ 3Ô∏è‚É£ Skrypt do generowania planu naprawy (`generate_plan.py`)

```python
from pathlib import Path
from ollama import Chat

# Wczytaj manifest i raport
manifest = Path("manifest.yaml").read_text()
combined_report = Path("reports/combined_report.json").read_text()

prompt = f"""
Manifest YAML:
{manifest}

B≈Çƒôdy i raporty:
{combined_report}

Na podstawie manifestu i raport√≥w, wygeneruj plan naprawy w YAML.
"""

# Wywo≈Çanie Ollama
response = Chat("your_model_name").send(prompt)

# Zapisz wynikowy plan
Path("reports/repair_plan.yaml").write_text(response.text)
print("Plan naprawy zapisany jako reports/repair_plan.yaml")
```

---

### üîπ 4Ô∏è‚É£ Wersja ‚Äúw jednej linii‚Äù (bash)

Po zainstalowaniu Ollama i Pythonowego klienta:

```bash
bash run_tests.sh && python collect_reports.py && python generate_plan.py
```

* Uruchamia testy i linty.
* ≈ÅƒÖczy raporty.
* Wysy≈Ça wszystko do Ollama.
* Zapisuje wynikowy plan naprawy w `reports/repair_plan.yaml`.

---

### üîπ üîπ Dodatkowe usprawnienia

1. Filtracja tylko krytycznych b≈Çƒôd√≥w do promptu, aby nie przeciƒÖ≈ºaƒá LLM.
2. Automatyczne generowanie nazwy folderu nowej iteracji w planie.
3. Mo≈ºliwo≈õƒá integracji w CI/CD: GitHub Actions, GitLab CI, Jenkins.









## üß∞ Najlepsze narzƒôdzia AI do pracy w terminalu

### 1. **AIChat**

* **Opis**: Wszechstronne narzƒôdzie CLI integrujƒÖce r√≥≈ºne modele LLM, takie jak OpenAI, Claude, Gemini, Ollama i inne. Umo≈ºliwia interakcjƒô z systemem plik√≥w, generowanie polece≈Ñ shellowych oraz korzystanie z agent√≥w AI.

* **Instalacja**:

  ```bash
  cargo install aichat
  ```

* **U≈ºycie**:

  ```bash
  aichat -e "Na podstawie wynik√≥w test√≥w i manifestu YAML, wygeneruj plan iteracji w YAML."
  ```

* **Zalety**: Obs≈Çuguje wiele modeli LLM, oferuje integracjƒô z systemem plik√≥w i umo≈ºliwia tworzenie agent√≥w AI.

### 2. **ShellGPT**

* **Opis**: Narzƒôdzie CLI umo≈ºliwiajƒÖce zadawanie pyta≈Ñ i generowanie polece≈Ñ shellowych za pomocƒÖ LLM. Obs≈Çuguje Linux, macOS i Windows z Bash, Zsh, PowerShell itp.

* **Instalacja**:

  ```bash
  npm install -g @thekitze/shellgpt
  ```

* **U≈ºycie**:

  ```bash
  sgpt "Na podstawie wynik√≥w test√≥w i manifestu YAML, wygeneruj plan iteracji w YAML."
  ```

* **Zalety**: Prosta integracja z terminalem, wsparcie dla wielu system√≥w operacyjnych.

### 3. **Lazyshell**

* **Opis**: Narzƒôdzie CLI generujƒÖce polecenia shellowe z naturalnego jƒôzyka za pomocƒÖ AI.

* **Instalacja**:

  ```bash
  cargo install lazyshell
  ```

* **U≈ºycie**:

  ```bash
  lazyshell "Na podstawie wynik√≥w test√≥w i manifestu YAML, wygeneruj plan iteracji w YAML."
  ```

* **Zalety**: Umo≈ºliwia generowanie polece≈Ñ shellowych z naturalnego jƒôzyka, co u≈Çatwia automatyzacjƒô zada≈Ñ.

### 4. **Butterfish**

* **Opis**: Narzƒôdzie CLI umo≈ºliwiajƒÖce zadawanie pyta≈Ñ dotyczƒÖcych historii polece≈Ñ shellowych, generowanie i autouzupe≈Çnianie polece≈Ñ shellowych oraz interakcjƒô z GPT.

* **Instalacja**:

  ```bash
  cargo install butterfish
  ```

* **U≈ºycie**:

  ```bash
  butterfish "Na podstawie wynik√≥w test√≥w i manifestu YAML, wygeneruj plan iteracji w YAML."
  ```

* **Zalety**: Integracja z historiƒÖ polece≈Ñ shellowych, wsparcie dla autouzupe≈Çniania polece≈Ñ.

### 5. **Warp**

* **Opis**: Nowoczesny emulator terminala z wbudowanƒÖ sztucznƒÖ inteligencjƒÖ, oferujƒÖcy sugestie polece≈Ñ i generowanie kodu.

* **Instalacja**:

  ```bash
  curl -fsSL https://warp.dev/install.sh | sh
  ```

* **U≈ºycie**:

  ```bash
  warp "Na podstawie wynik√≥w test√≥w i manifestu YAML, wygeneruj plan iteracji w YAML."
  ```

* **Zalety**: Zaawansowane funkcje AI, integracja z terminalem, wsparcie dla wsp√≥≈Çpracy zespo≈Çowej.

---

## üîß Przyk≈Çady zastosowania z manifestem YAML

Za≈Ç√≥≈ºmy, ≈ºe masz manifest YAML o nastƒôpujƒÖcej tre≈õci:

```yaml
project_manifest:
  metadata:
    project_name: "ExampleProject"
    current_iteration: 3
    vector_of_expectations: "Refaktoryzacja modu≈Ç√≥w API i uproszczenie test√≥w"
  
  principles:
    - id: 1
      title: "Specyfikacja to dopiero poczƒÖtek"
      description: "Sama specyfikacja nie wystarcza. Nale≈ºy wskazaƒá wektor rozwoju i priorytety."
      priority: high
      LLM_hint: "Skup siƒô na okre≈õleniu kierunku rozwoju projektu."
      example_use: |
        - "Okre≈õl kierunek rozwoju projektu."
        - "Zidentyfikuj funkcje i modu≈Çy kluczowe dla obecnej iteracji."
```

### üõ†Ô∏è Integracja z wynikami test√≥w

Po uruchomieniu test√≥w i zapisaniu wynik√≥w w pliku `test_report.json`, mo≈ºesz po≈ÇƒÖczyƒá je z manifestem YAML i przekazaƒá do narzƒôdzia AI:

```bash
cat manifest.yaml test_report.json | aichat -e "Na podstawie manifestu i wynik√≥w test√≥w, wygeneruj plan iteracji w YAML."
```

### üìÇ Automatyczne tworzenie struktury folder√≥w

Na podstawie wygenerowanego planu iteracji, mo≈ºesz automatycznie tworzyƒá odpowiedniƒÖ strukturƒô folder√≥w:

```bash
mkdir -p $(cat plan.yaml | grep 'folder_name' | awk '{print $2}')
```

---

## üìö Inne przydatne narzƒôdzia AI CLI

* **ShellGPT**: Narzƒôdzie CLI umo≈ºliwiajƒÖce zadawanie pyta≈Ñ i generowanie polece≈Ñ shellowych za pomocƒÖ LLM.

* **Lazyshell**: Narzƒôdzie CLI generujƒÖce polecenia shellowe z naturalnego jƒôzyka za pomocƒÖ AI.

* **Butterfish**: Narzƒôdzie CLI umo≈ºliwiajƒÖce zadawanie pyta≈Ñ dotyczƒÖcych historii polece≈Ñ shellowych, generowanie i autouzupe≈Çnianie polece≈Ñ shellowych oraz interakcjƒô z GPT.

* **Warp**: Nowoczesny emulator terminala z wbudowanƒÖ sztucznƒÖ inteligencjƒÖ, oferujƒÖcy sugestie polece≈Ñ i generowanie kodu.

* **AI Shell Agent**: Asystent AI dzia≈ÇajƒÖcy w terminalu, umo≈ºliwiajƒÖcy interakcjƒô z systemem plik√≥w i wykonywanie polece≈Ñ shellowych.

* **Raconteur**: Narzƒôdzie LLM do wyja≈õniania polece≈Ñ shellowych, oferujƒÖce zrozumia≈Çe wyja≈õnienia i kontekstowe informacje.

* **JELAI**: Platforma integrujƒÖca AI i analizƒô uczenia w notatnikach Jupyter, wspierajƒÖca interakcjƒô z kodem i analizƒô danych.

* **ChatCoT**: Framework do rozumowania z wykorzystaniem narzƒôdzi w modelach opartych na czacie, wspierajƒÖcy rozwiƒÖzywanie z≈Ço≈ºonych zada≈Ñ.

## üìö Dodatkowe zasoby

* [Ollama Tutorial: Running LLMs Locally Made Super Simple](https://www.kdnuggets.com/ollama-tutorial-running-llms-locally-made-super-simple)
* [Getting started with Ollama for Python](https://github.com/RamiKrispin/ollama-poc)
* [Step-by-Step Guide: Running LLM Models with Ollama](https://dev.to/snehalkadwe/how-to-setup-ollma-and-llm-4601)







# v2 Iteracyjne tworzenie projekt√≥w z LLM i manifestem YAML



## Lista obaw programisty

1. **Zbyt wiele folder√≥w iteracji**

   * Iteracje g≈Ç√≥wne, sub-iteracje funkcjonalno≈õci, eksperymenty, poprawki.
   * Trudno≈õƒá w odnalezieniu w≈Ça≈õciwej wersji.

2. **Duplikacja kodu**

   * Ka≈ºda iteracja tworzy nowe foldery i nowe pliki.
   * Powtarzanie funkcji, kt√≥re dzia≈Ça≈Çy wcze≈õniej.

3. **Nieefektywna refaktoryzacja**

   * Kolejne iteracje wymagajƒÖ zmian w wielu miejscach.
   * Trudno≈õƒá w ocenie, czy rozpoczƒÖƒá nowy folder czy kontynuowaƒá stary.

4. **ZarzƒÖdzanie testami i wynikami**

   * Ka≈ºda iteracja ma w≈Çasne testy, raporty i linty.
   * Trudno≈õƒá w por√≥wnywaniu wynik√≥w miƒôdzy iteracjami.

5. **Historia zmian**

   * Trudno ≈õledziƒá, kt√≥re iteracje by≈Çy stabilne, a kt√≥re nie.
   * ≈ÅƒÖczenie wiedzy miƒôdzy wersjami funkcjonalno≈õci.

6. **≈ÅƒÖczenie funkcjonalno≈õci**

   * Jedna funkcjonalno≈õƒá mo≈ºe mieƒá wiele sub-iteracji.
   * Trudno≈õƒá w integracji stabilnych fragment√≥w w kolejne wersje.

7. **ZarzƒÖdzanie manifestem**

   * Utrzymanie aktualnego manifestu w wielu iteracjach.
   * PowiƒÖzanie z poprzednimi iteracjami (`parent_iteration`).

8. **Automatyzacja workflow**

   * Pobieranie wynik√≥w test√≥w/lint√≥w i generowanie plan√≥w dzia≈Ça≈Ñ przez LLM.
   * Minimalizacja b≈Çƒôd√≥w manualnych.

9. **Archiwizacja starych iteracji**

   * Jak zachowaƒá historiƒô, a jednocze≈õnie utrzymaƒá porzƒÖdek.
   * Kompresja i ewentualne usuwanie niepotrzebnych folder√≥w.

10. **Kontekst LLM**

    * LLM ma ograniczonƒÖ pamiƒôƒá kontekstu.
    * Jak uniknƒÖƒá przeciƒÖ≈ºenia modelem przy wielu folderach i du≈ºych projektach.







## Cel

Celem jest stworzenie **systemu iteracyjnego rozwoju oprogramowania**, kt√≥ry umo≈ºliwia:

* Tworzenie kolejnych wersji funkcjonalno≈õci w uporzƒÖdkowany spos√≥b.
* Automatyzacjƒô test√≥w, lint√≥w i planowania dzia≈Ça≈Ñ przez LLM.
* Minimalizacjƒô duplikacji kodu i chaosu w strukturze folder√≥w.
* Utrzymanie historii i archiwizacjƒô starych iteracji.

---

## Kluczowe zasady

1. **Manifest YAML** jest centralnym punktem kontroli:

   * Opisuje ka≈ºdƒÖ iteracjƒô lub funkcjonalno≈õƒá.
   * Zawiera informacje o `parent_iteration`, `version`, `vector_of_expectations` i notatki.
   * Mo≈ºe definiowaƒá **generyczny schemat tworzenia kolejnych iteracji**.

2. **Izolacja iteracji i funkcjonalno≈õci**:

   * Ka≈ºda iteracja mo≈ºe byƒá folderem, modu≈Çem lub artefaktem (mikro-us≈Çuga, kontener, FaaS).
   * Wsp√≥lne funkcje umieszczamy w `common/`.

3. **Automatyzacja**:

   * Skrypty zbierajƒÖ raporty test√≥w/lint√≥w, integrujƒÖ je z manifestem i przekazujƒÖ do LLM.
   * LLM generuje plan kolejnej iteracji, strukturƒô folder√≥w i manifest.

4. **PorzƒÖdek i archiwizacja**:

   * Starsze iteracje kompresujemy lub przenosimy do `archive/`.
   * Mo≈ºna wersjonowaƒá pliki zamiast tworzyƒá nowe foldery dla drobnych zmian.

5. **Minimalizacja duplikacji**:

   * Dziedziczenie funkcji z `common/`.
   * Manifesty i LLM sugerujƒÖ, kt√≥re funkcje mo≈ºna odziedziczyƒá, zamiast kopiowaƒá.

---

## Obawy u≈ºytkownika i rozwiƒÖzania

| Obawa                         | RozwiƒÖzanie praktyczne                                                                   |
| ----------------------------- | ---------------------------------------------------------------------------------------- |
| Zbyt wiele folder√≥w           | Scal stabilne iteracje, wersjonowanie plik√≥w, archiwizacja eksperymentalnych iteracji.   |
| Duplikacja kodu               | `common/` dla funkcji wsp√≥≈Çdzielonych, LLM sugeruje odziedziczenie.                      |
| Nieefektywna refaktoryzacja   | Automatyzacja z LLM, manifest pokazuje zale≈ºno≈õci miƒôdzy iteracjami.                     |
| ZarzƒÖdzanie testami           | Wsp√≥lne testy w `tests/common`, specyficzne w iteracji. CI/CD automatyzuje uruchomienie. |
| Historia zmian                | Git + manifest + iterations\_map.yaml ‚Üí ≈Çatwa kontrola kolejnych iteracji.               |
| ≈ÅƒÖczenie funkcjonalno≈õci      | Manifesty i sub-iteracje pokazujƒÖ zale≈ºno≈õci i powiƒÖzania.                               |
| ZarzƒÖdzanie manifestem        | Manifest centralizuje metadane iteracji i schemat generowania kolejnych.                 |
| Automatyzacja workflow        | Skrypty zbierajƒÖ dane, LLM generuje plan, manifest i strukturƒô folder√≥w.                 |
| Archiwizacja starych iteracji | Kompresja, `archive/`, Git, Git LFS dla du≈ºych plik√≥w.                                   |
| Kontekst LLM                  | Manifest i podzia≈Ç na modu≈Çy/funkcje umo≈ºliwia analizƒô w ograniczonym kontek≈õcie.        |

---

## Struktura projektu (przyk≈Çad)

```
ExampleProject/
‚îú‚îÄ‚îÄ featureX_stable/
‚îÇ   ‚îú‚îÄ‚îÄ api_module_v3.py
‚îÇ   ‚îî‚îÄ‚îÄ tests/
‚îú‚îÄ‚îÄ featureY_stable/
‚îÇ   ‚îú‚îÄ‚îÄ api_module_v2.py
‚îÇ   ‚îî‚îÄ‚îÄ tests/
‚îú‚îÄ‚îÄ common/
‚îÇ   ‚îî‚îÄ‚îÄ utils.py
‚îú‚îÄ‚îÄ iterations_map.yaml
‚îú‚îÄ‚îÄ manifest.yaml
‚îî‚îÄ‚îÄ archive/
    ‚îú‚îÄ‚îÄ featureX/
    ‚îÇ   ‚îú‚îÄ‚îÄ iteration_1_failed/
    ‚îÇ   ‚îî‚îÄ‚îÄ iteration_2_partial/
    ‚îî‚îÄ‚îÄ featureY/
        ‚îî‚îÄ‚îÄ iteration_1/
```

## manifest YAML (generyczny schemat iteracji)

```yaml
project_manifest:
  project_name: "ExampleProject"
  description: "Generyczny schemat iteracyjnego rozwoju projektu z LLM"
  vector_of_expectations: "Uproszczenie kodu, automatyzacja test√≥w, izolacja funkcjonalno≈õci"

iteration_template:
  folder_pattern: "iteration_{number}_{feature}_{version}"
  manifest_template:
    iteration_number: "{number}"
    feature_name: "{feature}"
    version: "{version}"
    stable: false
    parent_iteration: "{parent_iteration}"
    notes: "{notes}"
  next_iteration_rules:
    increment_version: true
    new_feature: false
    fork_sub_iteration_if_experimental: true

structure_guidelines:
  common_libraries:
    folder: "common"
    description: "Funkcje wsp√≥≈Çdzielone"
  tests:
    folder: "tests"
    description: "Testy wsp√≥lne i specyficzne dla iteracji"
  rules:
    avoid_duplicate_code: true
    archive_old_iterations: true
    version_files_instead_of_folders: true
    lmm_generate_next_iteration: true
```

## 2Ô∏è‚É£ JSON Schema do walidacji manifestu

```json
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "Project Manifest Schema",
  "type": "object",
  "required": ["project_manifest", "iteration_template", "structure_guidelines"],
  "properties": {
    "project_manifest": {
      "type": "object",
      "required": ["project_name", "description", "vector_of_expectations"],
      "properties": {
        "project_name": {"type": "string"},
        "description": {"type": "string"},
        "vector_of_expectations": {"type": "string"}
      }
    },
    "iteration_template": {
      "type": "object",
      "required": ["folder_pattern", "manifest_template", "next_iteration_rules"],
      "properties": {
        "folder_pattern": {"type": "string"},
        "manifest_template": {
          "type": "object",
          "required": ["iteration_number", "feature_name", "version", "stable", "parent_iteration", "notes"],
          "properties": {
            "iteration_number": {"type": "string"},
            "feature_name": {"type": "string"},
            "version": {"type": "string"},
            "stable": {"type": "boolean"},
            "parent_iteration": {"type": "string"},
            "notes": {"type": "string"}
          }
        },
        "next_iteration_rules": {
          "type": "object",
          "properties": {
            "increment_version": {"type": "boolean"},
            "new_feature": {"type": "boolean"},
            "fork_sub_iteration_if_experimental": {"type": "boolean"}
          },
          "additionalProperties": false
        }
      }
    },
    "structure_guidelines": {
      "type": "object",
      "required": ["common_libraries", "tests", "rules"],
      "properties": {
        "common_libraries": {
          "type": "object",
          "required": ["folder", "description"],
          "properties": {
            "folder": {"type": "string"},
            "description": {"type": "string"}
          }
        },
        "tests": {
          "type": "object",
          "required": ["folder", "description"],
          "properties": {
            "folder": {"type": "string"},
            "description": {"type": "string"}
          }
        },
        "rules": {
          "type": "object",
          "required": ["avoid_duplicate_code", "archive_old_iterations", "version_files_instead_of_folders", "lmm_generate_next_iteration"],
          "properties": {
            "avoid_duplicate_code": {"type": "boolean"},
            "archive_old_iterations": {"type": "boolean"},
            "version_files_instead_of_folders": {"type": "boolean"},
            "lmm_generate_next_iteration": {"type": "boolean"}
          },
          "additionalProperties": false
        }
      },
      "additionalProperties": false
    }
  },
  "additionalProperties": false
}
```


## Jak u≈ºyƒá schematu do walidacji

### Python (przyk≈Çad):

```python
import yaml
import jsonschema

# Wczytaj manifest YAML
with open("manifest.yaml", "r") as f:
    manifest = yaml.safe_load(f)

# Wczytaj schemat JSON
with open("manifest_schema.json", "r") as f:
    schema = json.load(f)

# Walidacja
try:
    jsonschema.validate(instance=manifest, schema=schema)
    print("Manifest jest poprawny!")
except jsonschema.exceptions.ValidationError as e:
    print("B≈ÇƒÖd w manife≈õcie:", e)
```

---

## Korzy≈õci

* Automatyczna walidacja manifestu przed u≈ºyciem przez LLM lub skrypty.
* Zapobieganie b≈Çƒôdom w polach manifestu i strukturze folder√≥w.
* ≈Åatwe rozszerzenie schematu o dodatkowe regu≈Çy lub typy iteracji.
* LLM mo≈ºe generowaƒá nowƒÖ iteracjƒô i od razu sprawdziƒá poprawno≈õƒá YAML.



## Workflow przyk≈Çadowej iteracji

1. Uruchomienie test√≥w i lint√≥w dla aktualnej iteracji:

```bash
bash run_tests.sh
```

2. Po≈ÇƒÖczenie raport√≥w z manifestem:

```bash
python collect_reports.py
```

3. LLM generuje plan kolejnej iteracji:

```bash
python generate_plan.py
```

4. Tworzenie nowego folderu/artefaktu zgodnie z manifestem szablonowym.
5. Dodanie nowej iteracji do `iterations_map.yaml`.
6. Archiwizacja starych eksperymentalnych iteracji.

---

## 7 Korzy≈õci

* PorzƒÖdek w wielu iteracjach i funkcjonalno≈õciach.
* Automatyzacja planowania kolejnych iteracji z LLM.
* Minimalizacja duplikacji kodu.
* Historia i audyt iteracji.
* ≈Åatwe testowanie i deployment dziƒôki modularnej strukturze i artefaktom.



# v3 Rozszerzony manifest YAML

Dodajemy pola do **automatycznej analizy b≈Çƒôd√≥w i narzƒôdzi**, kt√≥re majƒÖ byƒá u≈ºyte:

```yaml
project_manifest:
  project_name: "ExampleProject"
  description: "Projekt rozwijany iteracyjnie z LLM i automatyzacjƒÖ analizy b≈Çƒôd√≥w"
  vector_of_expectations: "Uproszczenie kodu, automatyzacja test√≥w, izolacja funkcjonalno≈õci"

iteration_template:
  folder_pattern: "iteration_{number}_{feature}_{version}"
  manifest_template:
    iteration_number: "{number}"
    feature_name: "{feature}"
    version: "{version}"
    stable: false
    parent_iteration: "{parent_iteration}"
    notes: "{notes}"
  next_iteration_rules:
    increment_version: true
    new_feature: false
    fork_sub_iteration_if_experimental: true

structure_guidelines:
  common_libraries:
    folder: "common"
    description: "Funkcje wsp√≥≈Çdzielone"
  tests:
    folder: "tests"
    description: "Testy wsp√≥lne i specyficzne dla iteracji"
  rules:
    avoid_duplicate_code: true
    archive_old_iterations: true
    version_files_instead_of_folders: true
    lmm_generate_next_iteration: true

analysis_tools:
  - name: "pytest"
    path: "tests/"
    timeout: 30
  - name: "flake8"
    path: "src/"
    timeout: 10
  - name: "mypy"
    path: "src/"
    timeout: 10
```

W `analysis_tools` deklarujemy:

* Narzƒôdzia do analizy (testy, lint, typy),
* ≈öcie≈ºki, kt√≥re majƒÖ sprawdzaƒá,
* Timeout dla ka≈ºdej analizy (chroni przed zawieszeniem skryptu).

---

## Przyk≈Çadowy skrypt Python (`ymll`)

Skrypt automatycznie:

1. Wczytuje manifest YAML.
2. Uruchamia narzƒôdzia wskazane w `analysis_tools`.
3. Zbiera wyniki (raporty b≈Çƒôd√≥w).
4. Generuje **prompt dla LLM (`chatai`)** bazujƒÖc na manifestie i raportach.
5. Wywo≈Çuje LLM tylko z gotowym promptem.

```python
import yaml
import subprocess
import json
import shlex

# 1. Wczytanie manifestu
manifest_file = "manifest.yaml"  # developer wskazuje tylko ten plik
with open(manifest_file, "r") as f:
    manifest = yaml.safe_load(f)

tools = manifest.get("analysis_tools", [])

# 2. Uruchomienie narzƒôdzi z timeout i zebranie wynik√≥w
results = []
for tool in tools:
    cmd = f"{tool['name']} {tool['path']}"
    try:
        completed = subprocess.run(shlex.split(cmd), capture_output=True, text=True, timeout=tool.get("timeout", 30))
        results.append({
            "tool": tool['name'],
            "output": completed.stdout + "\n" + completed.stderr,
            "returncode": completed.returncode
        })
    except subprocess.TimeoutExpired:
        results.append({
            "tool": tool['name'],
            "output": "TIMEOUT",
            "returncode": -1
        })

# 3. Generowanie promptu dla LLM na podstawie manifestu i raport√≥w
prompt = f"""
Analizuj projekt {manifest['project_manifest']['project_name']}.

Vector of expectations: {manifest['project_manifest']['vector_of_expectations']}

Iteracja: {manifest['iteration_template']['manifest_template']['iteration_number']}
Feature: {manifest['iteration_template']['manifest_template']['feature_name']}
Folder: {manifest['iteration_template']['folder_pattern']}

Analiza wynik√≥w narzƒôdzi:
"""

for r in results:
    prompt += f"\nTool: {r['tool']}\nReturn code: {r['returncode']}\nOutput:\n{r['output']}\n"

prompt += "\nNa podstawie powy≈ºszych informacji wygeneruj plan kolejnej iteracji oraz sugestie napraw."

# 4. Zapis promptu do pliku
with open("prompt_for_chatai.txt", "w") as f:
    f.write(prompt)

print("Prompt dla chatai zosta≈Ç wygenerowany w pliku prompt_for_chatai.txt")
```

---

## U≈ºycie z LLM w shell

Po wygenerowaniu promptu przez `ymll`, LLM wykonuje prompt:

```bash
chatai run --prompt-file prompt_from_ymll.txt
```

* **Developer nie uruchamia test√≥w rƒôcznie**, nie analizuje b≈Çƒôd√≥w ‚Äì wszystko robi `ymll`.
* `chatai` tylko otrzymuje gotowy, kompletny prompt i generuje rekomendacje lub kod dla kolejnej iteracji.

---

## Zalety tego podej≈õcia

1. **Pe≈Çna automatyzacja** ‚Äì developer wskazuje tylko plik manifestu.
2. **Bezpieczne uruchamianie narzƒôdzi** ‚Äì timeout w manifestach chroni przed zawieszeniem.
3. **≈Åatwe rozszerzanie** ‚Äì dodajesz nowe narzƒôdzie do manifestu, `ymll` obs≈Çu≈ºy je automatycznie.
4. **Standaryzacja prompt√≥w** ‚Äì LLM zawsze otrzymuje sp√≥jny, kompletny kontekst.
5. **Integracja z iteracyjnym workflow** ‚Äì manifest, mapa iteracji i raporty test√≥w sƒÖ podstawƒÖ dla kolejnych iteracji.




# v4 

**developer wskazuje tylko manifest**, a ca≈Çy workflow ‚Äì analiza b≈Çƒôd√≥w, generowanie promptu, wywo≈Çanie `chatai`, tworzenie nowej iteracji, aktualizacja mapy i archiwizacja ‚Äì odbywa siƒô automatycznie.

## Zalety tego rozwiƒÖzania

* Developer **wskazuje tylko manifest** ‚Äì resztƒô wykonuje automatycznie skrypt `ymll`.
* **Automatyczne generowanie promptu dla `chatai`** uwzglƒôdnia manifest i wyniki narzƒôdzi testowych.
* **Tworzenie nowej iteracji i manifestu** w pe≈Çni automatyczne.
* **Archiwizacja starych iteracji** utrzymuje porzƒÖdek w projekcie.
* **Aktualizacja mapy iteracji** pozwala ≈õledziƒá historiƒô i zale≈ºno≈õci miƒôdzy iteracjami.


## Struktura projektu

Kompletny workflow: manifest ‚Üí analiza ‚Üí prompt ‚Üí chatai ‚Üí nowa iteracja ‚Üí aktualizacja mapy ‚Üí archiwizacja

```
ExampleProject/
‚îú‚îÄ‚îÄ src/
‚îú‚îÄ‚îÄ tests/
‚îú‚îÄ‚îÄ common/
‚îú‚îÄ‚îÄ manifest.yaml           # wskazany przez developera
‚îú‚îÄ‚îÄ iterations_map.yaml     # aktualna mapa iteracji
‚îú‚îÄ‚îÄ archive/                # stare iteracje
‚îú‚îÄ‚îÄ ymll/                   # skrypty automatyzujƒÖce
‚îÇ   ‚îú‚îÄ‚îÄ run_analysis.py
‚îÇ   ‚îú‚îÄ‚îÄ update_iterations.py
‚îÇ   ‚îî‚îÄ‚îÄ validate_manifest.py
‚îî‚îÄ‚îÄ prompt_for_chatai.txt    # wygenerowany automatycznie
```


## Workflow: manifest ‚Üí analiza ‚Üí prompt ‚Üí chatai ‚Üí nowa iteracja ‚Üí mapa ‚Üí archiwizacja

```
+----------------------+
|  Developer wskazuje  |
|   manifest.yaml      |
+---------+------------+
          |
          v
+---------------------------+
|  Skrypt ymll/run_analysis |
|  - Wczytuje manifest      |
|  - Uruchamia testy i lint |
|    (pytest, flake8, mypy) |
|  - Timeout dla narzƒôdzi   |
|  - Zbiera wyniki analizy  |
+------------+--------------+
             |
             v
+-----------------------------+
|  Generowanie promptu dla    |
|  chatai                     |
|  - Uwzglƒôdnia manifest      |
|  - Uwzglƒôdnia wyniki test√≥w |
|  - Tworzy kompletny kontekst|
+------------+----------------+
             |
             v
+-----------------------------+
|  Wywo≈Çanie chatai           |
|  - chatai run --prompt-file |
|    prompt_for_chatai.txt    |
|  - LLM generuje plan        |
|    kolejnej iteracji,       |
|    sugestie napraw          |
+------------+----------------+
             |
             v
+-----------------------------+
|  Tworzenie nowej iteracji   |
|  - Folder zgodny z wzorcem  |
|  - Kopiowanie common/       |
|  - Tworzenie manifestu      |
|    nowej iteracji           |
+------------+----------------+
             |
             v
+-----------------------------------+
|  Aktualizacja iterations_map.yaml |
|  - Dodanie nowej iteracji         |
|  - Archiwizacja starych iteracji  |
+------------+----------------------+
             |
             v
+---------------------------+
|  Gotowe do uruchomienia   |
|  kolejnej iteracji        |
+---------------------------+
```


## Kluczowe punkty diagramu

1. **Minimalna praca developera** ‚Äì wskazanie jedynie `manifest.yaml`.
2. **Automatyczna analiza b≈Çƒôd√≥w** ‚Äì `ymll/run_analysis.py` uruchamia narzƒôdzia, zbiera wyniki, generuje prompt.
3. **Generowanie promptu dla `chatai`** ‚Äì pe≈Çen kontekst: manifest + raporty test√≥w.
4. **Tworzenie nowej iteracji** ‚Äì nowy folder, manifest, kopiowanie wsp√≥lnych funkcji.
5. **Aktualizacja mapy iteracji i archiwizacja** ‚Äì porzƒÖdek w projekcie, zachowanie historii.

## Pliki

### Manifest YAML (`manifest.yaml`)

```yaml
project_manifest:
  project_name: "ExampleProject"
  description: "Projekt rozwijany iteracyjnie z LLM i automatyzacjƒÖ"
  vector_of_expectations: "Uproszczenie kodu, automatyzacja test√≥w, izolacja funkcjonalno≈õci"

iteration_template:
  folder_pattern: "iteration_{number}_{feature}_{version}"
  manifest_template:
    iteration_number: 3
    feature_name: "FeatureX"
    version: 1
    stable: false
    parent_iteration: "iteration_2_FeatureX_v1"
    notes: "Poprawa b≈Çƒôd√≥w i refaktoryzacja funkcji"
  next_iteration_rules:
    increment_version: true
    new_feature: false
    fork_sub_iteration_if_experimental: true

structure_guidelines:
  common_libraries:
    folder: "common"
    description: "Funkcje wsp√≥≈Çdzielone"
  tests:
    folder: "tests"
    description: "Testy wsp√≥lne i specyficzne dla iteracji"
  rules:
    avoid_duplicate_code: true
    archive_old_iterations: true
    version_files_instead_of_folders: true
    lmm_generate_next_iteration: true

analysis_tools:
  - name: "pytest"
    path: "tests/"
    timeout: 30
  - name: "flake8"
    path: "src/"
    timeout: 10
  - name: "mypy"
    path: "src/"
    timeout: 10
```


### Skrypt `ymll/run_analysis.py`

```python
import yaml
import subprocess
import shlex
from pathlib import Path
import os
import datetime

# 1. Wczytanie manifestu
manifest_file = "manifest.yaml"
with open(manifest_file, "r") as f:
    manifest = yaml.safe_load(f)

tools = manifest.get("analysis_tools", [])
results = []

# 2. Uruchomienie narzƒôdzi z timeout i zebranie wynik√≥w
for tool in tools:
    cmd = f"{tool['name']} {tool['path']}"
    try:
        completed = subprocess.run(shlex.split(cmd), capture_output=True, text=True, timeout=tool.get("timeout", 30))
        results.append({
            "tool": tool['name'],
            "returncode": completed.returncode,
            "output": completed.stdout + "\n" + completed.stderr
        })
    except subprocess.TimeoutExpired:
        results.append({
            "tool": tool['name'],
            "returncode": -1,
            "output": "TIMEOUT"
        })

# 3. Generowanie promptu dla chatai
prompt_lines = [
    f"Analizuj projekt {manifest['project_manifest']['project_name']}",
    f"Vector of expectations: {manifest['project_manifest']['vector_of_expectations']}",
    f"Iteracja: {manifest['iteration_template']['manifest_template']['iteration_number']}",
    f"Feature: {manifest['iteration_template']['manifest_template']['feature_name']}",
    f"Folder: {manifest['iteration_template']['folder_pattern']}",
    "\nAnaliza wynik√≥w narzƒôdzi:"
]

for r in results:
    prompt_lines.append(f"\nTool: {r['tool']}\nReturn code: {r['returncode']}\nOutput:\n{r['output']}")

prompt_lines.append("\nNa podstawie powy≈ºszych informacji wygeneruj plan kolejnej iteracji oraz sugestie napraw.")

prompt_text = "\n".join(prompt_lines)
Path("prompt_for_chatai.txt").write_text(prompt_text)
print("Prompt dla chatai zosta≈Ç wygenerowany w pliku prompt_for_chatai.txt")

# 4. Tworzenie nowej iteracji
new_iter_number = manifest['iteration_template']['manifest_template']['iteration_number'] + 1
feature = manifest['iteration_template']['manifest_template']['feature_name']
folder_name = f"iteration_{new_iter_number}_{feature}_v1"
Path(folder_name).mkdir(exist_ok=True)

# Kopiowanie wsp√≥lnych funkcji
os.system(f"cp -r common {folder_name}/")

# Tworzenie manifestu nowej iteracji
new_manifest = dict(manifest)
new_manifest['iteration_template']['manifest_template']['iteration_number'] = new_iter_number
new_manifest['iteration_template']['manifest_template']['parent_iteration'] = manifest['iteration_template']['folder_pattern']
Path(folder_name + "/manifest.yaml").write_text(yaml.dump(new_manifest))
print(f"Nowa iteracja utworzona w folderze {folder_name}")
```


### Skrypt `ymll/update_iterations.py`

```python
import yaml
from pathlib import Path
import shutil
import datetime

# Wczytanie mapy iteracji
map_file = "iterations_map.yaml"
if Path(map_file).exists():
    with open(map_file) as f:
        iterations_map = yaml.safe_load(f)
else:
    iterations_map = []

# Dane nowej iteracji
new_folder = "iteration_4_FeatureX_v1"
new_iteration = {
    "iteration": 4,
    "folder": new_folder,
    "stable": False,
    "parent_iteration": "iteration_3_FeatureX_v1",
    "notes": "Automatycznie wygenerowana iteracja po analizie test√≥w"
}

# Dodanie nowej iteracji
iterations_map.append(new_iteration)

# Archiwizacja starych iteracji
archive_dir = Path("archive")
archive_dir.mkdir(exist_ok=True)
for old_iter in iterations_map[:-1]:
    old_folder = Path(old_iter['folder'])
    if old_folder.exists():
        timestamp = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
        shutil.move(str(old_folder), str(archive_dir / f"{old_folder.name}_{timestamp}"))

# Zapis zaktualizowanej mapy iteracji
with open(map_file, "w") as f:
    yaml.dump(iterations_map, f)

print("Mapa iteracji zosta≈Ça zaktualizowana i stare iteracje zosta≈Çy zarchiwizowane.")
```

## Shell workflow (end-to-end)

1. **Uruchomienie analizy i wygenerowanie promptu dla `chatai`:**

```bash
python ymll/run_analysis.py
```

* Skrypt uruchamia testy (`pytest`), linty (`flake8`), typy (`mypy`) z timeoutami.
* Zbiera wyniki i generuje prompt dla `chatai` w pliku `prompt_for_chatai.txt`.


2. **Uruchomienie `chatai` z wygenerowanym promptem:**

```bash
chatai run --prompt-file prompt_for_chatai.txt
```

* `chatai` generuje plan kolejnej iteracji i rekomendacje napraw.
* LLM nie musi znaƒá struktury projektu ani narzƒôdzi ‚Äì wszystko jest w prompt.


3. **Aktualizacja mapy iteracji i archiwizacja starych iteracji:**

```bash
python ymll/update_iterations.py
```

* Folder wed≈Çug schematu: `iteration_{number}_{feature}_v{version}`.
* Kopiowanie wsp√≥lnych funkcji z `common/`.
* Tworzenie nowego manifestu iteracji na podstawie szablonu w `manifest.yaml`.
* `iterations_map.yaml` zostaje zaktualizowane o nowƒÖ iteracjƒô.
* Stare iteracje przenoszone sƒÖ do `archive/` z timestampem.
* Zachowujemy pe≈ÇnƒÖ historiƒô projektu bez za≈õmiecania g≈Ç√≥wnej struktury.



## LLM

katalog projektu z gotowymi skryptami instalacyjnymi i uruchomieniowymi dla wszystkich narzƒôdzi CLI, tak aby dzia≈Ça≈Çy niezale≈ºnie od dystrybucji Linuxa. Zrobimy to z u≈ºyciem **uniwersalnych polece≈Ñ** (`curl`, `pip`, `npm`, `xdg-open`) i sprawdzaniem systemu, aby `xdg-open` dzia≈Ça≈Ço te≈º na macOS (`open`).

Oto projektowa struktura katalogu:

```
llm/
‚îú‚îÄ aichat/
‚îÇ  ‚îú‚îÄ setup.sh
‚îÇ  ‚îî‚îÄ run.sh
‚îú‚îÄ gemini/
‚îÇ  ‚îú‚îÄ setup.sh
‚îÇ  ‚îî‚îÄ run.sh
‚îú‚îÄ ollama/
‚îÇ  ‚îú‚îÄ setup.sh
‚îÇ  ‚îî‚îÄ run.sh
‚îú‚îÄ aider/
‚îÇ  ‚îú‚îÄ setup.sh
‚îÇ  ‚îî‚îÄ run.sh
‚îú‚îÄ lms/
‚îÇ  ‚îú‚îÄ setup.sh
‚îÇ  ‚îî‚îÄ run.sh
‚îî‚îÄ README.md
```

---

## 1Ô∏è‚É£ aichat/setup.sh

```bash
#!/bin/bash
# Instalacja AIChat w systemach Linux/macOS

echo "Instalacja AIChat..."

# Instalacja pip, je≈õli nie istnieje
if ! command -v pip &> /dev/null; then
    echo "pip nie znaleziony, instalacja..."
    if [ -f /etc/debian_version ]; then
        sudo apt update && sudo apt install -y python3-pip
    elif [ -f /etc/redhat-release ]; then
        sudo yum install -y python3-pip
    else
        echo "Nieznana dystrybucja, zainstaluj pip rƒôcznie."
        exit 1
    fi
fi

pip install --user aichat

echo "AIChat zainstalowany."
```

## aichat/run.sh

```bash
#!/bin/bash
# Uruchomienie AIChat w katalogu projektu i otwarcie pliku w przeglƒÖdarce

if [ "$(uname)" == "Darwin" ]; then
    BROWSER_CMD="open"
else
    BROWSER_CMD="xdg-open"
fi

echo "Uruchamianie AIChat..."
aichat

# Przyk≈Çad otwarcia pliku HTML
$aichat -e "$BROWSER_CMD index.html"
```

---

## 2Ô∏è‚É£ gemini/setup.sh

```bash
#!/bin/bash
echo "Instalacja Gemini CLI..."

if ! command -v brew &> /dev/null; then
    echo "Homebrew nie zainstalowany. Instalacja..."
    /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
fi

brew install gemini

echo "Gemini CLI zainstalowany."
```

## gemini/run.sh

```bash
#!/bin/bash
if [ "$(uname)" == "Darwin" ]; then
    BROWSER_CMD="open"
else
    BROWSER_CMD="xdg-open"
fi

gemini
gemini "!$BROWSER_CMD docs/index.html"
```

---

## 3Ô∏è‚É£ ollama/setup.sh

```bash
#!/bin/bash
echo "Instalacja Ollama..."

curl https://ollama.com/install.sh | bash
ollama --version
echo "Ollama zainstalowana."
```

## ollama/run.sh

```bash
#!/bin/bash
if [ "$(uname)" == "Darwin" ]; then
    BROWSER_CMD="open"
else
    BROWSER_CMD="xdg-open"
fi

ollama run llama3:8b
ollama run llama3:8b "!$BROWSER_CMD build/index.html"
```

---

## 4Ô∏è‚É£ aider/setup.sh

```bash
#!/bin/bash
echo "Instalacja aider..."

if ! command -v npm &> /dev/null; then
    echo "npm nie znaleziony, instalacja Node.js..."
    if [ -f /etc/debian_version ]; then
        sudo apt update && sudo apt install -y nodejs npm
    elif [ -f /etc/redhat-release ]; then
        sudo yum install -y nodejs npm
    else
        echo "Nieznana dystrybucja, zainstaluj Node.js rƒôcznie."
        exit 1
    fi
fi

npm install -g aider
echo "aider zainstalowany."
```

## aider/run.sh

```bash
#!/bin/bash
if [ "$(uname)" == "Darwin" ]; then
    BROWSER_CMD="open"
else
    BROWSER_CMD="xdg-open"
fi

aider review
aider shell "!$BROWSER_CMD index.html"
```

---

## 5Ô∏è‚É£ lms/setup.sh

```bash
#!/bin/bash
echo "Instalacja LM Studio CLI..."
curl -fsSL https://lmstudio.ai/install.sh | bash
lms --version
echo "LM Studio CLI zainstalowany."
```

## lms/run.sh

```bash
#!/bin/bash
if [ "$(uname)" == "Darwin" ]; then
    BROWSER_CMD="open"
else
    BROWSER_CMD="xdg-open"
fi

lms exec "$BROWSER_CMD report.html"
```

---

### üîπ Uwagi ko≈Ñcowe

* Wszystkie skrypty sƒÖ **wielodystrosystemowe Linux/macOS** dziƒôki sprawdzeniu `uname` i `xdg-open`/`open`.
* Po sklonowaniu projektu nadaj uprawnienia wykonywalne:

```bash
chmod +x */setup.sh */run.sh
```

* Instalacja i uruchomienie ka≈ºdego narzƒôdzia:

```bash
./aichat/setup.sh
./aichat/run.sh
```


