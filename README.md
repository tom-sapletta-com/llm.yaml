# llm.yaml
manifest realizacji projektÃ³w przy uÅ¼yciu LLM

## Szkic
podczas wieloletniej pracy rozwijania oprogramowania z LLM-ami doszedÅ‚em do kilku wnioskÃ³w, ktÃ³re optymalizujÄ… czas dostarczenia oczekiwanych rezultatÃ³w:
- specyfikacja nie jest wystarczajÄ…ca do tworzenia
- konieczne jest okreÅ›lenie wektora rozwoju, czÄ™sto przy refaktoryzacji dochodzi do koneicznosci okreÅ›lenia wiÄ™kszej iloÅ›ci tetsÃ³w i twoprzy siÄ™ gÃ³Â©ka zadaÅ„
- Gdy dochodzimy do tej gÃ³rki zadaÅ„ potrzebujemy zadecydowaÄ‡ czy stworzyÄ‡nowy projekt od nowa z aktualna specyfikacja i okresleniem punktu wektoru oczekiwaÅ„
- kaÅ¼da iteracja wymaga kolejnego folderu, dlatego Å¼ Å‚atwiej jest coÅ› stworzyÄ‡ od nowa majÄ…c w gÅ‚owie aktualne doÅ›wiadczenia i niepowodzenia
- to niepowodzenia ksztaÅ‚tujÄ… wektor okreÅ›lajÄ…cy zakres prac i kierunek rozwoju
- kolejne iteracje nie powoinny polegaÄ‡ na zmianie aktualnych plikÃ³w, ale caÅ‚ej struktury, co jest nieintuicyjne dla czÅ‚owieka, ktÃ³ry z zasady chce naprawiÄ‡ to co nie dziaÅ‚a, gdyÅ¼ okontekÅ›t jest Å›ciÅ›le okreÅ›lony, jednak dla LLM to zbyt duÅ¼y wydatek energetyczny i muszÄ… skupiaÄ‡ siÄ™ na protszzych modelach, dlatego konieczny jest manifest uÅ‚atwiajÄ…cy radzenie sobie z konkretnymi problemami poporzez ich dzielnie na mniejsze i realziacje ich w nowych folderach



## Podsumowanie

Wnioski z pracy z LLM w projektach programistycznych

1. **Specyfikacja to dopiero poczÄ…tek**

   * Sama specyfikacja nie wystarczy, aby LLM generowaÅ‚y w peÅ‚ni funkcjonalny kod.
   * Trzeba rÃ³wnieÅ¼ okreÅ›liÄ‡ **kierunek rozwoju projektu** (â€wektor oczekiwaÅ„â€), ktÃ³ry pozwala decydowaÄ‡, co jest priorytetem w kolejnych iteracjach.

2. **Refaktoryzacja generuje gÃ³rkÄ™ zadaÅ„**

   * Podczas refaktoryzacji czÄ™sto okazuje siÄ™, Å¼e potrzeba wiÄ™cej testÃ³w i dodatkowych funkcji.
   * To tworzy â€gÃ³rkÄ™ zadaÅ„â€, ktÃ³rÄ… trzeba oceniÄ‡: czy lepiej kontynuowaÄ‡ obecny projekt, czy zaczÄ…Ä‡ od nowa.

3. **Decyzja: nowy projekt vs kontynuacja**

   * CzÄ™sto bardziej efektywne jest rozpoczÄ™cie nowego projektu z aktualnÄ… specyfikacjÄ… i nowym punktem startowym, niÅ¼ prÃ³ba naprawy istniejÄ…cego kodu.
   * DziÄ™ki temu unikamy nagromadzenia â€historycznychâ€ bÅ‚Ä™dÃ³w i nieoptymalnych struktur.

4. **Iteracje jako nowe foldery / struktury**

   * KaÅ¼da iteracja powinna byÄ‡ traktowana jako osobny projekt, a nie poprawka w istniejÄ…cych plikach.
   * Ludzki instynkt: â€naprawiÄ‡ to, co nie dziaÅ‚aâ€ jest nieoptymalny dla LLM, poniewaÅ¼ kontekst staje siÄ™ zbyt rozbudowany.
   * Lepsze: dzieliÄ‡ problemy na mniejsze czÄ™Å›ci i realizowaÄ‡ je w **nowych strukturach**, minimalizujÄ…c zaleÅ¼noÅ›ci od wczeÅ›niejszych iteracji.

5. **Niepowodzenia ksztaÅ‚tujÄ… kierunek rozwoju**

   * BÅ‚Ä™dy i nieudane iteracje nie sÄ… stratÄ… czasu â€“ to kluczowy element wyznaczania kolejnych krokÃ³w i punktÃ³w w wektorze rozwoju.
   * PozwalajÄ… LLM skupiÄ‡ siÄ™ na prostszych, bardziej precyzyjnych modelach problemu.

6. **Manifest dla pracy z LLM**

   * Stworzenie dokumentu / zasad, ktÃ³re pomagajÄ… radziÄ‡ sobie z problemami poprzez:

     * dzielenie ich na mniejsze, Å‚atwiejsze zadania,
     * realizacjÄ™ ich w nowych folderach/projektach,
     * zachowanie jasnego punktu startowego i minimalizacji kontekstu z poprzednich iteracji.


## PrzykÅ‚ady


- manifest w formacie YAML, ktÃ³ry LLM ma czytaÄ‡ i interpretowaÄ‡
- KaÅ¼dy punkt ma **opis**, **priorytet** oraz **zalecane dziaÅ‚ania**, Å¼eby model wiedziaÅ‚, co jest istotne w danej iteracji. 


### Manifest pracy z LLM â€“ YAML

```yaml
project_manifest:
  metadata:
    project_name: "ExampleProject"
    current_iteration: 3
    vector_of_expectations: "Refaktoryzacja moduÅ‚Ã³w API i uproszczenie testÃ³w"
  
  principles:
    - id: 1
      title: "Specyfikacja to dopiero poczÄ…tek"
      description: "Sama specyfikacja nie wystarcza. NaleÅ¼y wskazaÄ‡ wektor rozwoju i priorytety."
      priority: high
      LLM_hint: "Skup siÄ™ na okreÅ›leniu kierunku rozwoju projektu."
      example_use: |
        - "OkreÅ›l kierunek rozwoju projektu."
        - "Zidentyfikuj funkcje i moduÅ‚y kluczowe dla obecnej iteracji."

    - id: 2
      title: "Refaktoryzacja generuje gÃ³rkÄ™ zadaÅ„"
      description: "Refaktoryzacja czÄ™sto ujawnia dodatkowe wymagania i testy."
      priority: medium
      LLM_hint: "Zidentyfikuj nowe testy potrzebne do poprawnej refaktoryzacji."
      example_use: |
        - "Zidentyfikuj nowe testy potrzebne do poprawnej refaktoryzacji."
        - "OceÅ„, czy warto kontynuowaÄ‡ stary projekt, czy zaczÄ…Ä‡ nowy."

    - id: 3
      title: "Nowy projekt vs kontynuacja"
      description: "RozpoczÄ™cie nowego projektu moÅ¼e byÄ‡ bardziej efektywne niÅ¼ poprawa starego."
      priority: high
      LLM_hint: "OceÅ„, czy lepiej rozpoczÄ…Ä‡ nowy projekt, czy kontynuowaÄ‡ obecny."
      example_use: |
        - "UtwÃ³rz nowÄ… strukturÄ™ projektu, jeÅ›li obecna jest zbyt zÅ‚oÅ¼ona."
        - "Zachowaj doÅ›wiadczenia z poprzednich iteracji w dokumentacji."

    - id: 4
      title: "Iteracje jako nowe foldery/projekty"
      description: "KaÅ¼da iteracja powinna byÄ‡ osobnym projektem, unikajÄ…c zmiany starych plikÃ³w."
      priority: high
      LLM_hint: "TwÃ³rz nowy folder dla kaÅ¼dej iteracji."
      example_use: |
        - "TwÃ³rz nowy folder dla kaÅ¼dej iteracji."
        - "Podziel problem na mniejsze zadania realizowane w nowych strukturach."

    - id: 5
      title: "Niepowodzenia ksztaÅ‚tujÄ… kierunek rozwoju"
      description: "BÅ‚Ä™dy i nieudane iteracje sÄ… ÅºrÃ³dÅ‚em informacji o kierunku prac."
      priority: medium
      LLM_hint: "Dokumentuj niepowodzenia i wyciÄ…gaj z nich wnioski."
      example_use: |
        - "Dokumentuj niepowodzenia i wyciÄ…gaj z nich wnioski."
        - "Uaktualniaj wektor oczekiwaÅ„ na podstawie doÅ›wiadczeÅ„."

    - id: 6
      title: "Manifest jako przewodnik LLM"
      description: "Zasady manifestu pomagajÄ… LLM w efektywnej realizacji zadaÅ„."
      priority: high
      LLM_hint: "Dziel problemy na mniejsze, Å‚atwiejsze do wykonania zadania."
      example_use: |
        - "Dziel problemy na mniejsze, Å‚atwiejsze do wykonania zadania."
        - "Realizuj zadania w nowych folderach, aby minimalizowaÄ‡ kontekst z poprzednich iteracji."

```



### PrzykÅ‚ad uÅ¼ycia YAML przez LLM

ZaÅ‚Ã³Å¼my, Å¼e LLM dostaje zadanie: **Refaktoryzacja moduÅ‚u API w iteracji 3**.

1. Model odczytuje manifest i widzi:

   * `current_iteration: 3`
   * `vector_of_expectations: Refaktoryzacja moduÅ‚Ã³w API i uproszczenie testÃ³w`
   * Priorytetowe zasady: `Specyfikacja to dopiero poczÄ…tek`, `Iteracje jako nowe foldery`, `Nowy projekt vs kontynuacja`.

2. Model moÅ¼e zaplanowaÄ‡ dziaÅ‚ania:

```yaml
iteration_plan:
  iteration: 3
  actions:
    - "UtwÃ³rz nowy folder dla iteracji 3."
    - "Zidentyfikuj kluczowe moduÅ‚y API wymagajÄ…ce refaktoryzacji."
    - "Dodaj brakujÄ…ce testy dla moduÅ‚Ã³w API."
    - "Dokumentuj wszelkie problemy i niepowodzenia."
    - "Na podstawie doÅ›wiadczeÅ„ z poprzednich iteracji zaktualizuj wektor oczekiwaÅ„."
```

3. Efekt: LLM dziaÅ‚a zgodnie z manifestem, unika nadmiernego kontekstu z poprzednich iteracji i skupia siÄ™ na priorytetach.



## Ollama + manifest llm yaml

jak rozpoczÄ…Ä‡ pracÄ™ z Ollama i manifestami YAML, aby efektywnie zarzÄ…dzaÄ‡ iteracjami w projektach programistycznych?

---

## ğŸ§° Krok 1: Instalacja Ollama

### Na systemie Linux:

1. **Pobierz i zainstaluj Ollama:**

   ```bash
   curl -fsSL https://ollama.com/install.sh | sh
   ```

2. **SprawdÅº, czy instalacja siÄ™ powiodÅ‚a:**

   ```bash
   ollama --version
   ```

   JeÅ›li zobaczysz wersjÄ™ Ollama, oznacza to, Å¼e instalacja przebiegÅ‚a pomyÅ›lnie.


3. **Zainicjuj serwer Ollama:**

   ```bash
   ollama serve
   ```

4. **PrzekaÅ¼ manifest jako prompt do Ollama:**

   ```bash
   ollama chat --prompt "$(cat manifest.yaml)"
   ```

   Ollama odczyta manifest i na jego podstawie wygeneruje plan iteracji lub dziaÅ‚ania w oparciu o zawarte zasady.






Rozumiem, chcesz w peÅ‚ni **zautomatyzowaÄ‡ przepÅ‚yw informacji**: LLM dostaje wyniki testÃ³w, lintÃ³w i innych narzÄ™dzi, Å‚Ä…czy je z manifestem YAML i generuje plan dziaÅ‚aÅ„ w jednej, spÃ³jnej iteracji. MogÄ™ to rozbiÄ‡ na kroki i pokazaÄ‡ sposÃ³b, jak to zrobiÄ‡ praktycznie â€“ np. w shellu lub Pythonie.

---

## ğŸ”¹ Koncepcja automatyzacji

1. **Zbierz wszystkie wyniki narzÄ™dzi** w formacie tekstowym lub JSON:

   * `pytest --json-report` â†’ raport JSON z testÃ³w
   * `eslint -f json` â†’ raport JSON dla JS/TS
   * `flake8 --format=json` â†’ raport JSON dla Pythona
2. **PoÅ‚Ä…cz te raporty** w jednÄ… strukturÄ™, np. JSON z bÅ‚Ä™dami i metadanymi.
3. **PrzekaÅ¼ ten JSON + manifest YAML** do LLM jako prompt.
4. LLM analizuje:

   * bÅ‚Ä™dy / niepowodzenia
   * priorytety z manifestu (`LLM_hint`, `priority`)
   * wektor rozwoju i aktualnÄ… iteracjÄ™
5. LLM generuje **plan naprawy**, np. w YAML lub JSON gotowy do automatycznej realizacji.

---

## ğŸ”¹ PrzykÅ‚ad w jednej linii (bash + Ollama)

ZakÅ‚adajÄ…c, Å¼e masz:

* `manifest.yaml`
* `test_report.json` (wyniki testÃ³w, lintÃ³w itd.)

```bash
ollama chat --prompt "$(echo "Manifest YAML:"; cat manifest.yaml; echo; echo "BÅ‚Ä™dy i raporty:"; cat test_report.json; echo; echo "Na podstawie manifestu i raportÃ³w, wygeneruj plan naprawy w YAML.")"
```

* `$(echo ...)` â€“ scala manifest i raport w jednÄ… wiadomoÅ›Ä‡.
* LLM otrzymuje kontekst manifestu i konkretnych bÅ‚Ä™dÃ³w, wiÄ™c moÅ¼e wygenerowaÄ‡ **plan iteracji i naprawy**.

---

## ğŸ”¹ PrzykÅ‚ad w Pythonie 

```python
import json
from pathlib import Path
from ollama import Chat

# Wczytaj manifest i raport
manifest = Path("manifest.yaml").read_text()
report = Path("test_report.json").read_text()

prompt = f"""
Manifest YAML:
{manifest}

BÅ‚Ä™dy i raporty:
{report}

Na podstawie manifestu i raportÃ³w, wygeneruj plan naprawy w YAML.
"""

# WywoÅ‚anie Ollama
response = Chat("your_model_name").send(prompt)
print(response.text)
```

Efekt: LLM wygeneruje **iteracyjny plan dziaÅ‚aÅ„**, uwzglÄ™dniajÄ…cy priorytety i zalecenia z manifestu oraz konkretne problemy wykryte przez narzÄ™dzia.


[![Terminal GPT: UÅ¼yj ChatGPT w terminalu Linux bez kluczy API](https://tse2.mm.bing.net/th/id/OIP.a-367W9ib2ZqDIpy5cRxQAHaEK?pid=Api)](https://pl.ubunlog.com/terminal-gpt-tgpt/?utm_source=chatgpt.com)



## Projekt

1. Zbiera raporty z testÃ³w i lintÃ³w.
2. Scala je z manifestem YAML.
3. WysyÅ‚a do Ollama jako prompt.
4. Zapisuje wynikowy plan naprawy w YAML.

---

### ğŸ”¹ Struktura projektu

```
project/
â”œâ”€â”€ manifest.yaml
â”œâ”€â”€ run_tests.sh
â”œâ”€â”€ collect_reports.py
â”œâ”€â”€ generate_plan.py
â””â”€â”€ reports/
    â”œâ”€â”€ test_report.json
    â””â”€â”€ lint_report.json
```

---

### ğŸ”¹ 1ï¸âƒ£ Skrypt do uruchamiania testÃ³w i lintÃ³w (`run_tests.sh`)

```bash
#!/bin/bash
mkdir -p reports

# Uruchom testy Pythona i zapisz JSON
pytest --json-report --json-report-file=reports/test_report.json

# Uruchom linter Pythona i zapisz JSON
flake8 --format=json > reports/lint_report.json || true

echo "Raporty zapisane w folderze reports/"
```

> `|| true` zabezpiecza przed przerwaniem skryptu przy bÅ‚Ä™dach lint.

---

### ğŸ”¹ 2ï¸âƒ£ Skrypt do Å‚Ä…czenia raportÃ³w (`collect_reports.py`)

```python
import json
from pathlib import Path

# Wczytaj raporty
test_report = json.loads(Path("reports/test_report.json").read_text())
lint_report = json.loads(Path("reports/lint_report.json").read_text())

# PoÅ‚Ä…cz w jeden obiekt
combined_report = {
    "test_report": test_report,
    "lint_report": lint_report
}

# Zapisz do pliku JSON
Path("reports/combined_report.json").write_text(json.dumps(combined_report, indent=2))
print("PoÅ‚Ä…czony raport zapisany jako reports/combined_report.json")
```

---

### ğŸ”¹ 3ï¸âƒ£ Skrypt do generowania planu naprawy (`generate_plan.py`)

```python
from pathlib import Path
from ollama import Chat

# Wczytaj manifest i raport
manifest = Path("manifest.yaml").read_text()
combined_report = Path("reports/combined_report.json").read_text()

prompt = f"""
Manifest YAML:
{manifest}

BÅ‚Ä™dy i raporty:
{combined_report}

Na podstawie manifestu i raportÃ³w, wygeneruj plan naprawy w YAML.
"""

# WywoÅ‚anie Ollama
response = Chat("your_model_name").send(prompt)

# Zapisz wynikowy plan
Path("reports/repair_plan.yaml").write_text(response.text)
print("Plan naprawy zapisany jako reports/repair_plan.yaml")
```

---

### ğŸ”¹ 4ï¸âƒ£ Wersja â€œw jednej liniiâ€ (bash)

Po zainstalowaniu Ollama i Pythonowego klienta:

```bash
bash run_tests.sh && python collect_reports.py && python generate_plan.py
```

* Uruchamia testy i linty.
* ÅÄ…czy raporty.
* WysyÅ‚a wszystko do Ollama.
* Zapisuje wynikowy plan naprawy w `reports/repair_plan.yaml`.

---

### ğŸ”¹ ğŸ”¹ Dodatkowe usprawnienia

1. Filtracja tylko krytycznych bÅ‚Ä™dÃ³w do promptu, aby nie przeciÄ…Å¼aÄ‡ LLM.
2. Automatyczne generowanie nazwy folderu nowej iteracji w planie.
3. MoÅ¼liwoÅ›Ä‡ integracji w CI/CD: GitHub Actions, GitLab CI, Jenkins.









## ğŸ§° Najlepsze narzÄ™dzia AI do pracy w terminalu

### 1. **AIChat**

* **Opis**: Wszechstronne narzÄ™dzie CLI integrujÄ…ce rÃ³Å¼ne modele LLM, takie jak OpenAI, Claude, Gemini, Ollama i inne. UmoÅ¼liwia interakcjÄ™ z systemem plikÃ³w, generowanie poleceÅ„ shellowych oraz korzystanie z agentÃ³w AI.

* **Instalacja**:

  ```bash
  cargo install aichat
  ```

* **UÅ¼ycie**:

  ```bash
  aichat -e "Na podstawie wynikÃ³w testÃ³w i manifestu YAML, wygeneruj plan iteracji w YAML."
  ```

* **Zalety**: ObsÅ‚uguje wiele modeli LLM, oferuje integracjÄ™ z systemem plikÃ³w i umoÅ¼liwia tworzenie agentÃ³w AI.

### 2. **ShellGPT**

* **Opis**: NarzÄ™dzie CLI umoÅ¼liwiajÄ…ce zadawanie pytaÅ„ i generowanie poleceÅ„ shellowych za pomocÄ… LLM. ObsÅ‚uguje Linux, macOS i Windows z Bash, Zsh, PowerShell itp.

* **Instalacja**:

  ```bash
  npm install -g @thekitze/shellgpt
  ```

* **UÅ¼ycie**:

  ```bash
  sgpt "Na podstawie wynikÃ³w testÃ³w i manifestu YAML, wygeneruj plan iteracji w YAML."
  ```

* **Zalety**: Prosta integracja z terminalem, wsparcie dla wielu systemÃ³w operacyjnych.

### 3. **Lazyshell**

* **Opis**: NarzÄ™dzie CLI generujÄ…ce polecenia shellowe z naturalnego jÄ™zyka za pomocÄ… AI.

* **Instalacja**:

  ```bash
  cargo install lazyshell
  ```

* **UÅ¼ycie**:

  ```bash
  lazyshell "Na podstawie wynikÃ³w testÃ³w i manifestu YAML, wygeneruj plan iteracji w YAML."
  ```

* **Zalety**: UmoÅ¼liwia generowanie poleceÅ„ shellowych z naturalnego jÄ™zyka, co uÅ‚atwia automatyzacjÄ™ zadaÅ„.

### 4. **Butterfish**

* **Opis**: NarzÄ™dzie CLI umoÅ¼liwiajÄ…ce zadawanie pytaÅ„ dotyczÄ…cych historii poleceÅ„ shellowych, generowanie i autouzupeÅ‚nianie poleceÅ„ shellowych oraz interakcjÄ™ z GPT.

* **Instalacja**:

  ```bash
  cargo install butterfish
  ```

* **UÅ¼ycie**:

  ```bash
  butterfish "Na podstawie wynikÃ³w testÃ³w i manifestu YAML, wygeneruj plan iteracji w YAML."
  ```

* **Zalety**: Integracja z historiÄ… poleceÅ„ shellowych, wsparcie dla autouzupeÅ‚niania poleceÅ„.

### 5. **Warp**

* **Opis**: Nowoczesny emulator terminala z wbudowanÄ… sztucznÄ… inteligencjÄ…, oferujÄ…cy sugestie poleceÅ„ i generowanie kodu.

* **Instalacja**:

  ```bash
  curl -fsSL https://warp.dev/install.sh | sh
  ```

* **UÅ¼ycie**:

  ```bash
  warp "Na podstawie wynikÃ³w testÃ³w i manifestu YAML, wygeneruj plan iteracji w YAML."
  ```

* **Zalety**: Zaawansowane funkcje AI, integracja z terminalem, wsparcie dla wspÃ³Å‚pracy zespoÅ‚owej.

---

## ğŸ”§ PrzykÅ‚ady zastosowania z manifestem YAML

ZaÅ‚Ã³Å¼my, Å¼e masz manifest YAML o nastÄ™pujÄ…cej treÅ›ci:

```yaml
project_manifest:
  metadata:
    project_name: "ExampleProject"
    current_iteration: 3
    vector_of_expectations: "Refaktoryzacja moduÅ‚Ã³w API i uproszczenie testÃ³w"
  
  principles:
    - id: 1
      title: "Specyfikacja to dopiero poczÄ…tek"
      description: "Sama specyfikacja nie wystarcza. NaleÅ¼y wskazaÄ‡ wektor rozwoju i priorytety."
      priority: high
      LLM_hint: "Skup siÄ™ na okreÅ›leniu kierunku rozwoju projektu."
      example_use: |
        - "OkreÅ›l kierunek rozwoju projektu."
        - "Zidentyfikuj funkcje i moduÅ‚y kluczowe dla obecnej iteracji."
```

### ğŸ› ï¸ Integracja z wynikami testÃ³w

Po uruchomieniu testÃ³w i zapisaniu wynikÃ³w w pliku `test_report.json`, moÅ¼esz poÅ‚Ä…czyÄ‡ je z manifestem YAML i przekazaÄ‡ do narzÄ™dzia AI:

```bash
cat manifest.yaml test_report.json | aichat -e "Na podstawie manifestu i wynikÃ³w testÃ³w, wygeneruj plan iteracji w YAML."
```

### ğŸ“‚ Automatyczne tworzenie struktury folderÃ³w

Na podstawie wygenerowanego planu iteracji, moÅ¼esz automatycznie tworzyÄ‡ odpowiedniÄ… strukturÄ™ folderÃ³w:

```bash
mkdir -p $(cat plan.yaml | grep 'folder_name' | awk '{print $2}')
```

---

## ğŸ“š Inne przydatne narzÄ™dzia AI CLI

* **ShellGPT**: NarzÄ™dzie CLI umoÅ¼liwiajÄ…ce zadawanie pytaÅ„ i generowanie poleceÅ„ shellowych za pomocÄ… LLM.

* **Lazyshell**: NarzÄ™dzie CLI generujÄ…ce polecenia shellowe z naturalnego jÄ™zyka za pomocÄ… AI.

* **Butterfish**: NarzÄ™dzie CLI umoÅ¼liwiajÄ…ce zadawanie pytaÅ„ dotyczÄ…cych historii poleceÅ„ shellowych, generowanie i autouzupeÅ‚nianie poleceÅ„ shellowych oraz interakcjÄ™ z GPT.

* **Warp**: Nowoczesny emulator terminala z wbudowanÄ… sztucznÄ… inteligencjÄ…, oferujÄ…cy sugestie poleceÅ„ i generowanie kodu.

* **AI Shell Agent**: Asystent AI dziaÅ‚ajÄ…cy w terminalu, umoÅ¼liwiajÄ…cy interakcjÄ™ z systemem plikÃ³w i wykonywanie poleceÅ„ shellowych.

* **Raconteur**: NarzÄ™dzie LLM do wyjaÅ›niania poleceÅ„ shellowych, oferujÄ…ce zrozumiaÅ‚e wyjaÅ›nienia i kontekstowe informacje.

* **JELAI**: Platforma integrujÄ…ca AI i analizÄ™ uczenia w notatnikach Jupyter, wspierajÄ…ca interakcjÄ™ z kodem i analizÄ™ danych.

* **ChatCoT**: Framework do rozumowania z wykorzystaniem narzÄ™dzi w modelach opartych na czacie, wspierajÄ…cy rozwiÄ…zywanie zÅ‚oÅ¼onych zadaÅ„.

## ğŸ“š Dodatkowe zasoby

* [Ollama Tutorial: Running LLMs Locally Made Super Simple](https://www.kdnuggets.com/ollama-tutorial-running-llms-locally-made-super-simple)
* [Getting started with Ollama for Python](https://github.com/RamiKrispin/ollama-poc)
* [Step-by-Step Guide: Running LLM Models with Ollama](https://dev.to/snehalkadwe/how-to-setup-ollma-and-llm-4601)

